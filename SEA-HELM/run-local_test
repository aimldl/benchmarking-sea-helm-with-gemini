#!/bin/bash
# run-local_test
#   runs a local test with a specific model configuration.

set -euo pipefail

# Configure
MODEL_NAME="meta-llama/Llama-3-2-3B-Instruct"
OUTPUT_DIR="output_local_test"
MODEL_TYPE="litellm"

# Ensure the main script exists and is executable.
if [ ! -x "./run_evaluation.sh" ]; then
    echo "Error: 'run_evaluation.sh' was not found or is not executable." >&2
    echo "Ensure it exists in the current directory and has execute permissions." >&2
    echo "  $ chmod +x run_evaluation.sh" >&2
    exit 1
fi

# Run
python seahelm_evaluation.py --tasks seahelm --output_dir $OUTPUT_DIR --model_type litellm --model_name $MODEL_NAME --model_args "api_provider=ollama,base_url=http://localhost:11434"
#./run_evaluation.sh "$MODEL_NAME" "$OUTPUT_DIR" "$MODEL_TYPE"